{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Guided-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmay5/guided-research/blob/colab/Guided_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUEgRNmWuXym",
        "colab_type": "code",
        "outputId": "8d079e0d-1bcc-4de6-e9ae-8948e6dcf058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#installing all the libraries needed for the task\n",
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "from pandas.io.json import json_normalize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import re  \n",
        "from nltk.corpus import stopwords\n",
        "stops1 = set(stopwords.words(\"english\"))\n",
        "from Vocabulary import Vocab\n",
        "import pickle\n",
        "from torch.utils.data.sampler import Sampler\n",
        "import time\n",
        "import ipywidgets\n",
        "import traitlets\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyt5-NDhufaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_df = pd.read_pickle('./processed_df.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqpBLKBHSaXb",
        "colab_type": "text"
      },
      "source": [
        "#### These are the Vocabularies that are loaded via the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss01o4HiSfox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('vocab_combined.pkl','rb') as file:\n",
        "    recipe_vocabulary = pickle.load(file)\n",
        "    ingredient_vocabulary = pickle.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EypFef9Iu3ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(processed_df, test_size = 0.2, random_state = 0,\n",
        "                                     stratify=processed_df.Recipe_id_numeric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VczddQ3ZvESR",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i1SXOAhvAeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I am assuming that we are able to get the categories here\n",
        "# Now this should become a LSTM based model which will try and do binary prediction\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.utils.data.dataloader as dataloader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_lRNaeUvHc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some constants\n",
        "batch_size = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "120DuLyzvKR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/yunjey/seq2seq-dataloader/blob/master/data_loader.py\n",
        "def collate_fn(data):\n",
        "    \"\"\"Creates mini-batch tensors from the list of tuples (src_seq, trg_seq).\n",
        "    We should build a custom collate_fn rather than using default collate_fn,\n",
        "    because merging sequences (including padding) is not supported in default.\n",
        "    Seqeuences are padded to the maximum length of mini-batch sequences (dynamic padding).\n",
        "    Args:\n",
        "        data: list of tuple (src_seq, trg_seq).\n",
        "            - src_seq: torch tensor of shape (?); variable length.\n",
        "            - trg_seq: torch tensor of shape (?); variable length.\n",
        "    Returns:\n",
        "        src_seqs: torch tensor of shape (batch_size, padded_length).\n",
        "        src_lengths: list of length (batch_size); valid length for each padded source sequence.\n",
        "        trg_seqs: torch tensor of shape (batch_size, padded_length).\n",
        "        trg_lengths: list of length (batch_size); valid length for each padded target sequence.\n",
        "    \"\"\"\n",
        "    def merge(sequences):\n",
        "        lengths = [len(seq) for seq in sequences]\n",
        "        padded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
        "        for i, seq in enumerate(sequences):\n",
        "            end = lengths[i]\n",
        "            padded_seqs[i, :end] = seq[:end]\n",
        "        return padded_seqs, lengths\n",
        "\n",
        "    # sort a list by sequence length (descending order) to use pack_padded_sequence\n",
        "#     print(data[0]) # list of tuples\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "\n",
        "    # seperate source and target sequences\n",
        "    src_seqs, trg_seqs = zip(*data)\n",
        "\n",
        "    # merge sequences (from tuple of 1D tensor to 2D tensor)\n",
        "    src_seqs, src_lengths = merge(src_seqs)\n",
        "    # target sequence for us is a single tensor so we do not need to \n",
        "    # merge it\n",
        "    #trg_seqs, trg_lengths = merge(trg_seqs)\n",
        "    trg_seqs = torch.as_tensor(trg_seqs)\n",
        "    return src_seqs, src_lengths, trg_seqs #, trg_lengths\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxlQY20ivNRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RecipeData(data.Dataset):\n",
        "    \n",
        "    def __init__(self, df):\n",
        "        super(RecipeData, self).__init__()\n",
        "        self.df = df\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.as_tensor(self.df.Ingredient_Numeric.iloc[idx])\n",
        "        y = torch.as_tensor(self.df.Recipe_id_numeric.iloc[idx])\n",
        "        return X,y\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKfkbDRTFbPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_sample_count_train = df_train.Recipe_id_numeric.value_counts()\n",
        "class_sample_count_val = df_test.Recipe_id_numeric.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHw7xpfCMzDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class is imbalanced so let's handle this by weighted sampling\n",
        "# weights = 1 / torch.Tensor(class_sample_count_train)\n",
        "# sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, batch_size)\n",
        "train_dataset = RecipeData(df_train)\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           collate_fn=collate_fn,\n",
        "                                           drop_last=True,\n",
        "                                          #  sampler = sampler\n",
        "                                           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdpY4qExEmim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = RecipeData(df_test)\n",
        "# weights = 1 / torch.Tensor(class_sample_count_val)\n",
        "# sampler = torch.utils.data.sampler.WeightedRandomSampler()\n",
        "test_data_loader = torch.utils.data.DataLoader(dataset=test_dataset, # of the batch_size\n",
        "                                              batch_size=batch_size,\n",
        "                                              collate_fn=collate_fn,\n",
        "                                              drop_last=True,\n",
        "                                              # sampler=sampler\n",
        "                                               )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1o7a9BPvSea",
        "colab_type": "code",
        "outputId": "5eb9c1da-d225-4f77-96d4-fdce2cdb21d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_train.Recipe_id_numeric[4]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TUw5ZEavUid",
        "colab_type": "code",
        "outputId": "d4c2b975-644a-4575-9fb9-9da4e5d56b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([557,  20,  19,  38, 142,   3,  49]), tensor(11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ8uj-EovcGq",
        "colab_type": "code",
        "outputId": "18686092-7e6b-4998-a12b-0a8e2e80840f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "for idx, (X,X_len,y) in enumerate(test_data_loader):\n",
        "    # print(X)\n",
        "    # print(X_len)\n",
        "    print(idx)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySCeHYf4wotf",
        "colab_type": "code",
        "outputId": "a170c30c-9d0d-4169-b3ab-0f2f4d1c473c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Moving things to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbIWdzHt5lEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVSELkRt5ldW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmbeddingNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, hidden_dim, embedding_dim):\n",
        "        \n",
        "        super(EmbeddingNetwork, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_dim)\n",
        "        \n",
        "    def forward(self, input_sequence, max_len):\n",
        "#         print(input_sequence)\n",
        "#         print(max_len)\n",
        "        embedded = self.embedding(input_sequence)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, max_len, batch_first=True)\n",
        "        outputs, (self.c_n, self.h_n) = self.lstm(packed)\n",
        "        # Unpack padding\n",
        "        \"\"\"\n",
        "            Honestly, I do not know if at this point, I need the output. I would rather prefer to work with the\n",
        "            self.h_n cell and so will not `pad_padded_sequence`\n",
        "        \"\"\"\n",
        "        sequence_embedded, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "        # on which output should the prediction be done?\n",
        "        # self.h_n =  num_layers, batch_size, hidden_dim\n",
        "        batch_size = self.h_n.shape[1]\n",
        "        final_hidden_state = self.h_n.reshape(batch_size, -1)\n",
        "        return final_hidden_state, sequence_embedded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXk6NQ0g5lCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClassificationNetwork(nn.Module):\n",
        "    \n",
        "    \n",
        "    def __init__(self, embedding_model, hidden_dim, num_classes):\n",
        "        super(ClassificationNetwork, self).__init__()\n",
        "        self.embedding_model = embedding_model\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, input_sequence, max_len):\n",
        "        \n",
        "        final_hidden_state, _ = self.embedding_model(input_sequence, max_len)\n",
        "        output_predicted = self.linear(final_hidden_state)\n",
        "        return output_predicted\n",
        "\n",
        "    def get_embedder(self):\n",
        "      return self.embedding_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLHwSBKyvioY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are some constants that I am just copying here\n",
        "# These need to be updated based on the files\n",
        "ingredient_vocabulary = 1152\n",
        "recipe_vocabulary = 33\n",
        "vocab_size = ingredient_vocabulary + 1\n",
        "num_recipes = recipe_vocabulary + 1\n",
        "hidden_dim = 128\n",
        "embedding_dim = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaOZEq4H5k_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_model = EmbeddingNetwork(vocab_size=vocab_size, \n",
        "                                   hidden_dim=hidden_dim, embedding_dim=embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NTr8pXJ8b24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ClassificationNetwork(embedding_model=embedding_model, \n",
        "                              hidden_dim=hidden_dim,\n",
        "                              num_classes=vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIP9G3HYF4tA",
        "colab_type": "text"
      },
      "source": [
        "### I did not put hidden state on cuda and that was an issue. So, it has been corrected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiQj9hZ9Fnjr",
        "colab_type": "code",
        "outputId": "3794f506-4117-48d7-df07-d9e41e2b51f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificationNetwork(\n",
              "  (embedding_model): EmbeddingNetwork(\n",
              "    (embedding): Embedding(1153, 300)\n",
              "    (lstm): LSTM(300, 128)\n",
              "  )\n",
              "  (linear): Linear(in_features=128, out_features=1153, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7hXmWlfweTd",
        "colab_type": "text"
      },
      "source": [
        "## Put loss function and categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY3ua9PjwaDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5PcLdrwhYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epoch = 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4-G8nsMw_yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def put_elements_to_device(a,b,c,device):\n",
        "    return a.to(device), b.to(device), c.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_AIg_EfxEGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -q tb-nightly\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqaoUggYxHN8",
        "colab_type": "code",
        "outputId": "d6e25a8f-f089-471f-c964-f3f82d381fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh9-L_aWctgO",
        "colab_type": "code",
        "outputId": "f38767be-6e7e-4bef-af4e-8c16c0582425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_data_loader)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMXBPIJRG96w",
        "colab_type": "code",
        "outputId": "42c8631a-c74b-4db5-e476-0ec3e1d80129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(train_data_loader) * batch_size)\n",
        "print(len(train_dataset))\n",
        "# Not same since we are dropping some terms which do not match up\n",
        "N_train = len(train_data_loader) * batch_size\n",
        "N_test = len(test_data_loader) * batch_size"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79000\n",
            "79948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoI8ALwwWnhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_model_name = \"./lstm_model_epoch-{}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upzCHjdDxKfh",
        "colab_type": "code",
        "outputId": "32efedf1-b5a6-45ec-c399-aaa6df44ab03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(num_epoch):\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for idx,(X,X_len,y) in enumerate(train_data_loader):\n",
        "        # model.train()No batch norm used yet\n",
        "        model.zero_grad()\n",
        "        X, X_len, y = put_elements_to_device(a=X, b=torch.tensor(X_len), c=y, device=device)\n",
        "        outputs = model(X, X_len)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_loss =+ loss.item() * X.size(0)\n",
        "        total += X.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "    print('Accuracy of the network on the train samples: %d %%' % (\n",
        "        100 * correct / total))\n",
        "    # writer.add_scalar('Loss/train', running_loss/N_train, epoch)\n",
        "    # validation set is still left to create\n",
        "    # Now to test the validation set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for idx,(X,X_len,y) in enumerate(test_data_loader):\n",
        "            X, X_len, y = put_elements_to_device(a=X, b=torch.tensor(X_len), c=y, device=device)\n",
        "            outputs = model(X,X_len)\n",
        "            loss = criterion(outputs, y)\n",
        "            test_loss += loss.item() * X.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += X.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "    # writer.add_scalar('Loss/test', test_loss/N_test, epoch)\n",
        "    writer.add_scalars('loss_curves',\n",
        "                       {'train':running_loss/len(train_dataset), 'test':test_loss/len(test_dataset)},\n",
        "                       epoch)\n",
        "    print('Accuracy of the network on the test samples: %d %%' % (\n",
        "        100 * correct / total))\n",
        "    torch.save(model.state_dict(),save_model_name.format(epoch))    \n",
        "            "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the train samples: 59 %\n",
            "Accuracy of the network on the test samples: 66 %\n",
            "Accuracy of the network on the train samples: 70 %\n",
            "Accuracy of the network on the test samples: 71 %\n",
            "Accuracy of the network on the train samples: 72 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 73 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 74 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 75 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 75 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 76 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 76 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 77 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 77 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 78 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 78 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 79 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 79 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 80 %\n",
            "Accuracy of the network on the test samples: 73 %\n",
            "Accuracy of the network on the train samples: 80 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 81 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 81 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 82 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 83 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 83 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 84 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 85 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 85 %\n",
            "Accuracy of the network on the test samples: 72 %\n",
            "Accuracy of the network on the train samples: 86 %\n",
            "Accuracy of the network on the test samples: 71 %\n",
            "Accuracy of the network on the train samples: 86 %\n",
            "Accuracy of the network on the test samples: 71 %\n",
            "Accuracy of the network on the train samples: 87 %\n",
            "Accuracy of the network on the test samples: 71 %\n",
            "Accuracy of the network on the train samples: 88 %\n",
            "Accuracy of the network on the test samples: 71 %\n",
            "Accuracy of the network on the train samples: 88 %\n",
            "Accuracy of the network on the test samples: 71 %\n",
            "Accuracy of the network on the train samples: 88 %\n",
            "Accuracy of the network on the test samples: 70 %\n",
            "Accuracy of the network on the train samples: 88 %\n",
            "Accuracy of the network on the test samples: 70 %\n",
            "Accuracy of the network on the train samples: 88 %\n",
            "Accuracy of the network on the test samples: 69 %\n",
            "Accuracy of the network on the train samples: 88 %\n",
            "Accuracy of the network on the test samples: 69 %\n",
            "Accuracy of the network on the train samples: 89 %\n",
            "Accuracy of the network on the test samples: 68 %\n",
            "Accuracy of the network on the train samples: 90 %\n",
            "Accuracy of the network on the test samples: 68 %\n",
            "Accuracy of the network on the train samples: 91 %\n",
            "Accuracy of the network on the test samples: 69 %\n",
            "Accuracy of the network on the train samples: 92 %\n",
            "Accuracy of the network on the test samples: 69 %\n",
            "Accuracy of the network on the train samples: 92 %\n",
            "Accuracy of the network on the test samples: 69 %\n",
            "Accuracy of the network on the train samples: 93 %\n",
            "Accuracy of the network on the test samples: 68 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRsG_xSgxLUM",
        "colab_type": "code",
        "outputId": "1f58d747-612b-4bda-948c-fc54c8b5f96a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# !pip install tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FfhkBTky24z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip uninstall tensorboard\n",
        "# !pip install --force-reinstall tf-nightly-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j27ZU8Xvc8ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZZ6SCcQc8bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_sGkpb3c9aw",
        "colab_type": "text"
      },
      "source": [
        "##TSNE Portion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQksxamSdNmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHdVu25kdlKO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AUwKdz4dDN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWRxIcbTzZVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_list = []\n",
        "y_list = []\n",
        "with torch.no_grad():\n",
        "    for  idx,(X,X_len,y) in enumerate(test_data_loader):\n",
        "            \n",
        "            X, X_len, y = put_elements_to_device(a=X, b=torch.tensor(X_len), c=y, device=device)\n",
        "            \n",
        "            X_list.append(embedding_model(X, X_len)[0])\n",
        "            y_list.append(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSpcTrGlcn9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_combined = torch.cat(X_list,0)\n",
        "y_combined = torch.cat(y_list,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtkKJHZBcn6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X_combined.cpu().numpy()\n",
        "y = y_combined.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGwZbGsncn2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_ids = list(range(recipe_vocabulary))# binary classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyuR4QP3cnyt",
        "colab_type": "code",
        "outputId": "9ed93e11-1efc-4b5b-d41c-f61e43e8d078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(X)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[t-SNE] Computing 121 nearest neighbors...\n",
            "[t-SNE] Indexed 19000 samples in 0.109s...\n",
            "[t-SNE] Computed neighbors for 19000 samples in 94.791s...\n",
            "[t-SNE] Computed conditional probabilities for sample 1000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 2000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 3000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 4000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 5000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 6000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 7000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 8000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 9000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 10000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 11000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 12000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 13000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 14000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 15000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 16000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 17000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 18000 / 19000\n",
            "[t-SNE] Computed conditional probabilities for sample 19000 / 19000\n",
            "[t-SNE] Mean sigma: 4.405858\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 96.539131\n",
            "[t-SNE] KL divergence after 300 iterations: 4.557790\n",
            "t-SNE done! Time elapsed: 156.88042974472046 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovvi7wbfq1AQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import colors as mcolors\n",
        "\n",
        "colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
        "# Sort colors by hue, saturation, value and name.\n",
        "by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgba(color)[:3])), name)\n",
        "                for name, color in colors.items())\n",
        "sorted_names = [name for hsv, name in by_hsv]\n",
        "\n",
        "colors = sorted_names[:9 * len(target_ids): 14]\n",
        "# colors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbb0At5_czMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "e0ba5968-baa4-495c-d946-bb82baac2e5f"
      },
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "for i, c in zip(target_ids, colors):\n",
        "    plt.scatter(tsne_results[y == i, 0], tsne_results[y == i, 1], c=c)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEvCAYAAABYNEogAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBnIioopjICciqjgGciKiivv/8YIEEXpr550AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXuJ8M-6czJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqWL0-nNczGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvf-7qBaIpe8",
        "colab_type": "text"
      },
      "source": [
        "## The best model has been chosen and we load vectors for everything else"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9DxZm9Zzgmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "76ec1938-be7f-4617-a888-9d11571ff6fd"
      },
      "source": [
        "processed_df.iloc[5]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ingredients           [orange, clove, apple, water, cinnamon]\n",
              "Recipe_id                            The Spiced Cider Project\n",
              "Ingredient_Numeric                       [27, 28, 29, 24, 30]\n",
              "Recipe_id_numeric                                           0\n",
              "Name: 5, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rClW4wDUU2M3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recipe is entered\n",
        "recipe = \"The Spiced Cider Project\" # to be obtained as input later\n",
        "recipe_id = processed_df.Recipe_id.get(recipe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JRuQGQwbxo6",
        "colab_type": "text"
      },
      "source": [
        "# Just checking stuff here :(\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMUfzRZbqKwp",
        "colab_type": "text"
      },
      "source": [
        "#### One can take 1000 samples here and simply stack them on top of each other, then pass through the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFvOEnIWZi-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "7e86c16f-627a-4cf7-c223-aacd4a11a35c"
      },
      "source": [
        "# Ingredient_Numeric\n",
        "ingreds = processed_df.iloc[5].Ingredient_Numeric\n",
        "ingreds = (torch.as_tensor(ingreds)).unsqueeze(0)\n",
        "embeddings = model.embedding(torch.as_tensor(ingreds).cuda()) #tensor needed\n",
        "#embeddings.shape\n",
        "# Let us pass this through the LSTM :)\n",
        "output, _ = model.lstm(embeddings)\n",
        "output.squeeze_(0)\n",
        "output.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-9d429e9ed73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mingreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIngredient_Numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mingreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tensor needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#embeddings.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Let us pass this through the LSTM :)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ClassificationNetwork' object has no attribute 'embedding'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgWgXEcfIu3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IngredientEmbedding(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(IngredientEmbedding, self).__init__()\n",
        "    self.ingredient_embedding = dict() # A list for all ingredients\n",
        "    \n",
        "  def add_constituents(self, ingred_list, embedding):\n",
        "    for idx, ingred  in enumerate(ingred_list):\n",
        "        self.ingredient_embedding[ingred] = embedding[idx]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return str(self.ingredient_embedding.keys())\n",
        "    \n",
        "  def get_embeddings(self):\n",
        "    x = [ value for (key, value) in self.ingredient_embedding.items()]\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wA8gBxAtA0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ingreds = processed_df.iloc[5].Ingredient_Numeric\n",
        "ingredient_embedding = IngredientEmbedding()\n",
        "ingredient_embedding.add_constituents(ingreds, output)\n",
        "ingredient_embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtH0qrL6xjoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ingredient_embedding.get_embeddings()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nMqUnD9Mrjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now I want to put things into the Recipe object\n",
        "class Recipe(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Recipe,self).__init__()\n",
        "    self.ingred_embedding = IngredientEmbedding()\n",
        "\n",
        "  def create(self, id, name, ingred, numeric, embeddings):\n",
        "    self.common_id = id\n",
        "    self.name = name\n",
        "    self.IngredientNumeric = numeric\n",
        "    self.Ingredients = ingred\n",
        "    self.ingred_embedding = embeddings\n",
        "  \n",
        "  def get_repr(self):\n",
        "    return (self.common_id, self.Ingredients)\n",
        "\n",
        "  def get_embeddings(self):\n",
        "    return self.ingred_embedding.get_embeddings()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDCPIw2IyY2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_element = processed_df.iloc[5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzo8glDdxyDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_recipe = Recipe()\n",
        "my_recipe.create(id=sample_element.Recipe_id_numeric,\n",
        "                 name=sample_element.Recipe_id,\n",
        "                 ingred=sample_element.Ingredients,\n",
        "                 numeric=sample_element.Ingredients,\n",
        "                 embeddings=ingredient_embedding\n",
        "                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-vxOesm4jzm",
        "colab_type": "text"
      },
      "source": [
        "## tSNE visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUIf651T98R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedder = model.get_embedder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tNW3BwW-A4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us work with only the Non-zero column to see if there is any learning at all\n",
        "df_temp = processed_df[processed_df.Recipe_id_numeric > 0]\n",
        "df_temp.groupby('Recipe_id_numeric').count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5OcUzdCzCLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a hacky solution\n",
        "# I am passing all elements in a single batch\n",
        "# so that they can be stacked\n",
        "# num_samples = batch_size = 1000\n",
        "train_dataset_tsne = RecipeData(df_temp)\n",
        "sampler = torch.utils.data.RandomSampler(train_dataset_tsne, replacement=True, num_samples=1000)\n",
        "train_data_loader_tsne = torch.utils.data.DataLoader(dataset=train_dataset_tsne,\n",
        "                                              batch_size=1000,\n",
        "                                              collate_fn=collate_fn,\n",
        "                                               drop_last=True,\n",
        "                                               sampler = sampler\n",
        "                                               ) # Done for cases when num_samples not exact multiple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-nojIMS4np9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tsne = []\n",
        "y_tsne = []\n",
        "with torch.no_grad():\n",
        "    for idx,(X,X_len,y) in enumerate(train_data_loader_tsne):\n",
        "            X, X_len, y = put_elements_to_device(a=X, b=torch.tensor(X_len), c=y, device=device)\n",
        "            h_n, seq_embed = embedder(X, X_len)\n",
        "            flatten_seq_embed = seq_embed.reshape(seq_embed.size(0), -1)\n",
        "            X_tsne.append(flatten_seq_embed)\n",
        "            y_tsne.append(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1w1WsWZ5Ax8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_combined = torch.cat(X_tsne,0)\n",
        "y_combined = torch.cat(y_tsne,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b47Ruf435AwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X_combined.cpu().numpy()\n",
        "y = y_combined.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE-coBnS5Aua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_ids = class_vector.numpy() # binary classification\n",
        "target_ids = target_ids.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw1WkmV15ArN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(X)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtISJh_mOavv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors as mcolors\n",
        "\n",
        "colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
        "# Sort colors by hue, saturation, value and name.\n",
        "by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgba(color)[:3])), name)\n",
        "                for name, color in colors.items())\n",
        "sorted_names = [name for hsv, name in by_hsv]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj0jvXhAOast",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colors = sorted_names[:9 * len(class_vector): 14]\n",
        "colors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpMT3V6Y5Z-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "for i, c in zip(target_ids, colors):\n",
        "    plt.scatter(tsne_results[y == i, 0], tsne_results[y == i, 1], c=c)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c0v8Owq5abu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-QCz2nG5ahs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}