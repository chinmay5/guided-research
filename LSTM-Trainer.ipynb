{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 432kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from nltk)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/chinmay/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/chinmay/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/chinmay/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#installing all the libraries needed for the task\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from pandas.io.json import json_normalize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import re  \n",
    "from nltk.corpus import stopwords\n",
    "stops1 = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: boto3 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: boto>=2.32 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: requests in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.156 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.156->boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.156->boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: seaborn in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: pytz>=2011k in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn)\n",
      "Requirement already satisfied: six>=1.5 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: setuptools in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: elasticsearch in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from elasticsearch)\n",
      "Requirement already satisfied: esengine in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six==1.10.0 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from esengine)\n",
      "Requirement already satisfied: python-dateutil in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from esengine)\n",
      "Requirement already satisfied: ipdb in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages\n",
      "Requirement already satisfied: setuptools in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from ipdb)\n",
      "Requirement already satisfied: ipython>=5.1.0 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from ipdb)\n",
      "Requirement already satisfied: backcall in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: decorator in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: pickleshare in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: pygments in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: wcwidth in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: ipython-genutils in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb)\n",
      "Requirement already satisfied: parso>=0.3.0 in /home/chinmay/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages (from jedi>=0.10->ipython>=5.1.0->ipdb)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim\n",
    "! pip install seaborn\n",
    "! pip install elasticsearch\n",
    "! pip install esengine\n",
    "! pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/chinmay/Desktop/TUM/Sem-4/GuidedResearch/MyAttempts/github-code-guided-research/\n",
    "from Vocabulary import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chinmay/Desktop/TUM/Sem-4/GuidedResearch/MyAttempts\n"
     ]
    }
   ],
   "source": [
    "%cd /home/chinmay/Desktop/TUM/Sem-4/GuidedResearch/MyAttempts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "from sub_find import *\n",
    "from true_subs import *\n",
    "from constants import *\n",
    "# from graph_evaluation import *\n",
    "# from Vocabulary import Vocab\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipe import Recipe\n",
    "def load_data_from_file(filename=None, ing_file_name=None, local=True, save=False):\n",
    "    return load_data(file_name=filename, ing_file_name=ing_file_name, local=local, save=save)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('raw_data')\n",
    "recipes = load_data_from_file(\"100k/100ksample\", ing_file_name = \"dbpedia_ingredients.txt\",local=True, save=False )\n",
    "clean_recipes = [x.proccessed_ing_list for x in recipes]\n",
    "recipes = load_data_from_file(\"100k/100ksample2\", \"dbpedia_ingredients.txt\")\n",
    "sample100k2 = [x.proccessed_ing_list for x in recipes]\n",
    "clean_recipes.extend(sample100k2) \n",
    "type(clean_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "# currently looking only on the second set of elements\n",
    "total_number_of_recipes = len(recipes)\n",
    "print(total_number_of_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_present = set()\n",
    "for reduced_recipe_object in recipes:\n",
    "  titles_present.add(str(reduced_recipe_object.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Cajun Spice Blend',\n",
       " 'title': 'Cajun Spice Blend',\n",
       " 'instructions_text': 'mix together and store in airtight container and use as wanted.',\n",
       " 'ingredients_text': '1 tablespoon garlic powder 1 tablespoon onion powder 1 tablespoon sugar 1 teaspoon salt 1 teaspoon pepper 1 teaspoon dried basil 1 teaspoon paprika 12 teaspoon cayenne pepper',\n",
       " 'proccessed_ing_list': ['garlic powder',\n",
       "  'onion powder',\n",
       "  'sugar',\n",
       "  'cayenne pepper']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(recipes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['garlic powder', 'onion powder', 'sugar', 'cayenne pepper'],\n",
       " 'Cajun Spice Blend')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset = [(x.proccessed_ing_list, x.id) for x in recipes]\n",
    "final_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us use nltk to perform stemming. That way, it is possible to get the matches better\n",
    "# eg muffins and muffin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "# type(titles_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_title(word):\n",
    "    return stemmer.stem(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'carsons chicken wellington w/ exotic mushroom sherry sauc'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example\n",
    "stem_title('Carsons Chicken Wellington W/ Exotic Mushroom Sherry Sauce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_title = [stem_title(title) for title in titles_present]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recipe_titles_stemmed.txt', 'w') as file:\n",
    "    for item in updated_title:\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = 'cake,pasta,custard,rolls,stew,casserole,sauce,soup,burgers,pizza,salad,muffins,steaks,fish,ham'.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vindhya_list = ['Cake', 'Salad', 'Noodles', 'Hummus', 'Burger', 'Steak', 'Pie', 'Chicken', 'Custard', 'Chips',\n",
    "                'Casserole', 'Pasta', 'Pizza', 'Omelette', 'soup', 'sauce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31123"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the recipe matches\n",
    "# https://stackoverflow.com/questions/6531482/how-to-check-if-a-string-contains-an-element-from-a-list-in-python\n",
    "counter = 0\n",
    "for reduced_recipe_object in recipes:\n",
    "    # Honestly this is a shitty attempt since I already did the stemming earlier\n",
    "    # however, I am doing the same again\n",
    "    counter = counter +  any (stem_title(title) in stem_title(reduced_recipe_object.id) for title in vindhya_list)\n",
    "    \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.123\n"
     ]
    }
   ],
   "source": [
    "percentage_covered = counter / total_number_of_recipes * 100\n",
    "print(percentage_covered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eventually we will be using the cleaned recipe list for our evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so sample 100k2\n",
    "final_dataset = [(x.proccessed_ing_list, x.id) for x in recipes]\n",
    "only_ingredients = [i[0] for i in final_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Fix the code here. I just used glove pretrined so things can be ignored for a while here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_vocabulary = Vocab()\n",
    "for recipe in only_ingredients:\n",
    "    for ingredients in recipe:\n",
    "        ingredient_vocabulary.add_word(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us see the vocabulary size once\n",
    "ingredient_vocabulary.max_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hamburger'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_vocabulary.get_word(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(final_dataset, columns =['Ingredients', 'Recipe_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ingredients    [orange, clove, apple, water, cinnamon]\n",
       "Recipe_id                     The Spiced Cider Project\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We plan to use the gensim model as well. We create another pickle file with the Word2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-03 23:57:42--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.242.214\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.242.214|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1,5G) [application/x-gzip]\n",
      "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>]   1,53G  1,65MB/s    in 32m 57s \n",
      "\n",
      "2019-12-04 00:30:41 (814 KB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (3000000, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-438f08434cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' gzip -d GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpretrained_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1492\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1493\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (3000000, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "! wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "! gzip -d GoogleNews-vectors-negative300.bin.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "pretrained_embedding = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a sample check to indicate things are working as expected\n",
    "pretrained_embedding.vocab['orange'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is more of a hack\n",
    "def recipe_vocab_on_list(ingedient_list):\n",
    "    result_list = []\n",
    "    for ingedient in ingedient_list:\n",
    "        # If multi word ingredient, chose the first word\n",
    "        ingedient = ingedient.split(\" \")[0]\n",
    "        try:\n",
    "            result_list.append(pretrained_embedding.vocab[ingedient].index)\n",
    "        except KeyError:\n",
    "            result_list.append(pretrained_embedding.vocab['unk'].index)\n",
    "    return result_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ingredient_Numeric'] = df.Ingredients.apply(recipe_vocab_on_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_vocabulary = Vocab()\n",
    "for recipe in vindhya_list:\n",
    "    recipe_vocabulary.add_word(stemmer.stem(recipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recipe_vocabulary.word_2_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_vocabulary.check_any_word_in_vocab(stemmer.stem('The Spiced Cake Project'))\n",
    "# recipe_vocabulary.get_idx('cake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe_idx(recipe):\n",
    "    recipe_stemmed = stemmer.stem(recipe)\n",
    "    lookup_result = recipe_vocabulary.check_any_word_in_vocab(recipe_stemmed)\n",
    "    if lookup_result[0]:\n",
    "        return recipe_vocabulary.get_idx(lookup_result[1])\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recipe_idx('The Spiced Cake Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Recipe_id_numeric'] = df.Recipe_id.apply(get_recipe_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     78650\n",
       "11     5466\n",
       "8      3373\n",
       "7      3011\n",
       "2      1617\n",
       "6      1442\n",
       "10     1091\n",
       "12     1016\n",
       "1       973\n",
       "13      897\n",
       "5       761\n",
       "15      733\n",
       "14      546\n",
       "3       212\n",
       "4       120\n",
       "9        92\n",
       "Name: Recipe_id_numeric, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Recipe_id_numeric.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am pickling both the vocabularies which would be useful later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_combined.pkl','wb') as file:\n",
    "    pickle.dump(recipe_vocabulary, file)\n",
    "    pickle.dump(ingredient_vocabulary, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us drop the empty entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_empty(x):\n",
    "    return len(x) == 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = df.drop(df[df.Ingredient_Numeric.apply(check_empty)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(processed_df.Ingredient_Numeric.apply(check_empty)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am just saving the file here for reference later\n",
    "pd.to_pickle(processed_df, './processed_df_pretrained.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us build the two set of data using sklearn dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(processed_df, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the Neural Network portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am assuming that we are able to get the categories here\n",
    "# Now this should become a LSTM based model which will try and do binary prediction\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/yunjey/seq2seq-dataloader/blob/master/data_loader.py\n",
    "def collate_fn(data):\n",
    "    \"\"\"Creates mini-batch tensors from the list of tuples (src_seq, trg_seq).\n",
    "    We should build a custom collate_fn rather than using default collate_fn,\n",
    "    because merging sequences (including padding) is not supported in default.\n",
    "    Seqeuences are padded to the maximum length of mini-batch sequences (dynamic padding).\n",
    "    Args:\n",
    "        data: list of tuple (src_seq, trg_seq).\n",
    "            - src_seq: torch tensor of shape (?); variable length.\n",
    "            - trg_seq: torch tensor of shape (?); variable length.\n",
    "    Returns:\n",
    "        src_seqs: torch tensor of shape (batch_size, padded_length).\n",
    "        src_lengths: list of length (batch_size); valid length for each padded source sequence.\n",
    "        trg_seqs: torch tensor of shape (batch_size, padded_length).\n",
    "        trg_lengths: list of length (batch_size); valid length for each padded target sequence.\n",
    "    \"\"\"\n",
    "    def merge(sequences):\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        padded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
    "        for i, seq in enumerate(sequences):\n",
    "            end = lengths[i]\n",
    "            padded_seqs[i, :end] = seq[:end]\n",
    "        return padded_seqs, lengths\n",
    "\n",
    "    # sort a list by sequence length (descending order) to use pack_padded_sequence\n",
    "#     print(data[0]) # list of tuples\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "    # seperate source and target sequences\n",
    "    src_seqs, trg_seqs = zip(*data)\n",
    "\n",
    "    # merge sequences (from tuple of 1D tensor to 2D tensor)\n",
    "    src_seqs, src_lengths = merge(src_seqs)\n",
    "    # target sequence for us is a single tensor so we do not need to \n",
    "    # merge it\n",
    "    #trg_seqs, trg_lengths = merge(trg_seqs)\n",
    "    trg_seqs = torch.as_tensor(trg_seqs)\n",
    "    return src_seqs, src_lengths, trg_seqs #, trg_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeData(data.Dataset):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        super(RecipeData, self).__init__()\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.as_tensor(self.df.Ingredient_Numeric.iloc[idx])\n",
    "        y = torch.as_tensor(self.df.Recipe_id_numeric.iloc[idx])\n",
    "        return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RecipeData(df_train)\n",
    "test_dataset = RecipeData(df_test)\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                               drop_last=True) # Done for cases when num_samples not exact multiple\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset=test_dataset, # of the batch_size\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Recipe_id_numeric[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 65,  33, 140,  36]), tensor(0))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 19,   3, 174,  39,  95,  30,  52,  18, 225,   8,  38],\n",
      "        [130, 281,  38, 721,  24,  69, 129, 287, 278, 131,   0],\n",
      "        [486, 331,  23, 187,  80, 401, 185, 186, 341,   0,   0],\n",
      "        [131, 167, 151, 263,  61, 292,  52,  30,   0,   0,   0],\n",
      "        [129,   3,  94, 137, 196,   0,   0,   0,   0,   0,   0]])\n",
      "[11, 10, 9, 8, 5]\n",
      "tensor([1, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for (X,X_len,y) in train_data_loader:\n",
    "    print(X)\n",
    "    print(X_len)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 19,   3, 174,  39,  95,  30,  52,  18, 225,   8,  38],\n",
       "        [130, 281,  38, 721,  24,  69, 129, 287, 278, 131,   0],\n",
       "        [486, 331,  23, 187,  80, 401, 185, 186, 341,   0,   0],\n",
       "        [131, 167, 151, 263,  61, 292,  52,  30,   0,   0,   0],\n",
       "        [129,   3,  94, 137, 196,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipePredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_dim, embedding_dim, batch_size, output_dim):\n",
    "        super(RecipePredictor, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_dim)\n",
    "        self.batch_size = batch_size\n",
    "        self.predictor = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        self.non_linearity = nn.ReLU()\n",
    "        self.init_hidden() # TODO:  This should happen at the beginning of each epoch\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        self.h_n = torch.randn(1, self.batch_size, self.hidden_dim)\n",
    "        self.c_n = torch.randn(1, self.batch_size, self.hidden_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_sequence, max_len):\n",
    "#         print(input_sequence)\n",
    "#         print(max_len)\n",
    "        embedded = self.embedding(input_sequence)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, max_len, batch_first=True)\n",
    "        outputs, (self.c_n, self.h_n) = self.lstm(packed, (self.c_n, self.h_n))\n",
    "        # Unpack padding\n",
    "        \"\"\"\n",
    "            Honestly, I do not know if at this point, I need the output. I would rather prefer to work with the\n",
    "            self.h_n cell and so will not `pad_padded_sequence`\n",
    "        \"\"\"\n",
    "        #outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        # on which output should the prediction be done?\n",
    "        # self.h_n =  num_layers, batch_size, hidden_dim\n",
    "        batch_size = self.h_n.shape[1]\n",
    "        output_predicted = self.predictor(self.h_n.reshape(batch_size, -1))\n",
    "        return output_predicted\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = ingredient_vocabulary.max_idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_recipes = recipe_vocabulary.max_idx+1\n",
    "model = RecipePredictor(vocab_size=vocab_size, hidden_dim=512, embedding_dim=300, batch_size=batch_size,\n",
    "                       output_dim=num_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0401,  0.2132,  0.0743, -0.1556,  0.0510,  0.1881, -0.0421,  0.1119,\n",
       "          0.0713,  0.1193,  0.0347, -0.0798, -0.1863, -0.0639, -0.1612, -0.0156],\n",
       "        [ 0.0567,  0.0471,  0.0292,  0.0956, -0.0449, -0.0879, -0.0174, -0.1688,\n",
       "          0.1125, -0.1681,  0.0670, -0.1165,  0.0689,  0.0322, -0.0800,  0.0156],\n",
       "        [-0.0313,  0.0320, -0.0326,  0.1923,  0.1740, -0.0895, -0.0408,  0.0142,\n",
       "          0.0165, -0.0118,  0.0636, -0.0233, -0.2884,  0.2130,  0.0235,  0.1105],\n",
       "        [ 0.1292, -0.0452,  0.1735,  0.2075, -0.1769,  0.0785,  0.1529, -0.1209,\n",
       "          0.1062,  0.1867,  0.0799, -0.0008,  0.0811, -0.1242,  0.0404, -0.1528],\n",
       "        [ 0.0271, -0.1232,  0.3260,  0.1704,  0.0706,  0.0453,  0.0249,  0.1153,\n",
       "          0.2356, -0.0587,  0.2022, -0.1504, -0.0504, -0.0279, -0.0954, -0.0797]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X, X_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put loss function, gradient and try to train the lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Moving things to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecipePredictor(\n",
       "  (embedding): Embedding(1153, 300)\n",
       "  (lstm): LSTM(300, 512)\n",
       "  (predictor): Linear(in_features=512, out_features=16, bias=True)\n",
       "  (non_linearity): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_elements_to_device(a,b,c,device):\n",
    "    return a.to(device), b.to(device), c.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tb-nightly\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79945\n",
      "79948\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_loader) * batch_size)\n",
    "print(len(df_train))\n",
    "# Not same since we are dropping some terms which do not match up\n",
    "N_train = len(train_data_loader) * batch_size\n",
    "N_test = len(test_data_loader) * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 2.0085887908935547\n",
      "epoch 0 loss 102.51984167844057\n",
      "epoch 0 loss 221.88543963432312\n",
      "epoch 0 loss 312.94191985577345\n",
      "epoch 0 loss 409.68190402537584\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-1cfb2f3d2809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/i2dl_exercise/venv/sample_environment/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    running_loss = 0\n",
    "    model.init_hidden()\n",
    "    for idx,(X,X_len,y) in enumerate(train_data_loader):\n",
    "        model.zero_grad()\n",
    "        X, X_len, y = put_elements_to_device(a=X, b=torch.tensor(X_len), c=y, device=device)\n",
    "        prediction = model(X, X_len)\n",
    "        loss = criterion(prediction, y)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if idx % 100 == 0:\n",
    "            print(\"epoch {} loss {}\".format(epoch, running_loss))\n",
    "    writer.add_scalar('Loss/train', running_loss/N_train, epoch)\n",
    "    # validation set is still left to create\n",
    "    # Now to test the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for idx,(X,X_len,y) in enumerate(test_data_loader):\n",
    "            X, X_len, y = put_elements_to_device(a=X, b=torch.tensor(X_len), c=y, device=device)\n",
    "            outputs = model(X,X_len)\n",
    "            loss = criterion(outputs, y)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += X.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    writer.add_scalar('Loss/train', test_loss/N_test, epoch)\n",
    "    print('Accuracy of the network on the test samples: %d %%' % (\n",
    "        100 * correct / total))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b38ff8d3f76344ce\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b38ff8d3f76344ce\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vindhya_data_df = pd.read_csv('./recipe_title_foodCategory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cake',\n",
       " 'Salad',\n",
       " 'Noodles',\n",
       " 'Hummus',\n",
       " 'Burger',\n",
       " 'Steak',\n",
       " 'Pie',\n",
       " 'Chicken',\n",
       " 'Custard',\n",
       " 'Chips',\n",
       " 'Casserole',\n",
       " 'Pasta',\n",
       " 'Pizza',\n",
       " 'Omelette']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(vindhya_data_df.Food_Category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]\n",
    "b = ['a','b','c','d','e']\n",
    "c = ['dil','me','dard','e','disco']\n",
    "sallu_bhoi = zip(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = zip(*sallu_bhoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
